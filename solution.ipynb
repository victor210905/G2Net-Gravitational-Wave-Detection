{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "source": [
    "# **Imports & Environment Setup**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-25T15:05:46.349414Z",
     "iopub.status.busy": "2025-11-25T15:05:46.348575Z",
     "iopub.status.idle": "2025-11-25T15:05:54.432478Z",
     "shell.execute_reply": "2025-11-25T15:05:54.431374Z",
     "shell.execute_reply.started": "2025-11-25T15:05:46.349385Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'repr' attribute with value False was provided to the `Field()` function, which has no effect in the context it was used. 'repr' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'frozen' attribute with value True was provided to the `Field()` function, which has no effect in the context it was used. 'frozen' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import warnings\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import timm\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.cuda.amp import autocast, GradScaler\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "# Suppress warnings for cleaner output\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Install dependencies silently\n",
    "!pip install nnAudio timm > /dev/null 2>&1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Utility Module**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-25T15:05:54.434866Z",
     "iopub.status.busy": "2025-11-25T15:05:54.434091Z",
     "iopub.status.idle": "2025-11-25T15:05:54.442296Z",
     "shell.execute_reply": "2025-11-25T15:05:54.441742Z",
     "shell.execute_reply.started": "2025-11-25T15:05:54.434840Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting utils.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile utils.py\n",
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset\n",
    "import scipy.signal\n",
    "import scipy.interpolate\n",
    "from scipy.signal.windows import tukey\n",
    "\n",
    "try:\n",
    "    from nnAudio.Spectrogram import CQT1992v2\n",
    "except ImportError:\n",
    "    pass\n",
    "\n",
    "SOS_FILTER = scipy.signal.butter(4, [20, 500], btype=\"bandpass\", output=\"sos\", fs=2048)\n",
    "NORMALIZATION_FACTOR = np.sqrt((500 - 20) / (2048 / 2))\n",
    "WINDOW_TUKEY = tukey(4096, alpha=0.1)\n",
    "\n",
    "\n",
    "class ProjectConfig:\n",
    "    \"\"\"Centralized configuration for paths.\"\"\"\n",
    "    ROOT_DIR = '/kaggle/working'\n",
    "    DATA_DIR = '/kaggle/input/g2net-gravitational-wave-detection/train'\n",
    "    CSV_PATH = '/kaggle/input/g2net-gravitational-wave-detection/training_labels.csv'\n",
    "\n",
    "def seed_everything(seed=42):\n",
    "    \"\"\"Ensures reproducibility across runs.\"\"\"\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed(seed)\n",
    "        torch.backends.cudnn.benchmark = True \n",
    "        torch.backends.cudnn.deterministic = False\n",
    "\n",
    "# --- Signal Processing (High Performance) ---\n",
    "\n",
    "def apply_bandpass(x):\n",
    "    return scipy.signal.sosfiltfilt(SOS_FILTER, x) / NORMALIZATION_FACTOR\n",
    "\n",
    "def apply_whitening(x, sr=2048):\n",
    "    # 1. Windowing\n",
    "    x = x * WINDOW_TUKEY\n",
    "    \n",
    "    # 2. Calculate PSD (Power Spectral Density)\n",
    "    freqs, psd = scipy.signal.welch(x, fs=sr, nperseg=sr, window='hann')\n",
    "    \n",
    "    # 3. FFT (Fast Fourier Transform)\n",
    "    x_f = np.fft.rfft(x)\n",
    "    freqs_f = np.fft.rfftfreq(len(x), d=1/sr)\n",
    "    \n",
    "    valid_indices = (freqs_f >= freqs.min()) & (freqs_f <= freqs.max())\n",
    "    x_f_whitened = np.zeros_like(x_f)\n",
    "    \n",
    "    # 4. Interpolation\n",
    "    psd_values = np.interp(freqs_f[valid_indices], freqs, psd)\n",
    "    \n",
    "    # 5. Normalize & IFFT\n",
    "    x_f_whitened[valid_indices] = x_f[valid_indices] / np.sqrt(psd_values + 1e-20)\n",
    "    return np.fft.irfft(x_f_whitened, n=len(x))\n",
    "\n",
    "def apply_timeshift(x, max_shift=0.2, sr=2048):\n",
    "    shift_amt = int(random.random() * max_shift * sr)\n",
    "    if random.random() > 0.5:\n",
    "        shift_amt = -shift_amt\n",
    "    return np.roll(x, shift_amt, axis=-1)\n",
    "\n",
    "# --- Model Components ---\n",
    "\n",
    "class WaveToImage(nn.Module):\n",
    "    def __init__(self, sr=2048, fmin=20, fmax=1024, hop_length=64, device='cuda'):\n",
    "        super().__init__()\n",
    "        self.transform = CQT1992v2(sr=sr, fmin=fmin, fmax=fmax, hop_length=hop_length, \n",
    "                                   output_format=\"Magnitude\", verbose=False)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        batch_size, channels, time_steps = x.shape\n",
    "        x = x.view(batch_size * channels, time_steps)\n",
    "        images = self.transform(x)\n",
    "        _, h, w = images.shape\n",
    "        return images.view(batch_size, channels, h, w)\n",
    "\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, dataframe, root_dir, stage='train', augment=False):\n",
    "        self.df = dataframe\n",
    "        self.root_dir = root_dir\n",
    "        self.stage = stage\n",
    "        self.augment = augment\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.df.iloc[idx]\n",
    "        file_id = str(row['id'])\n",
    "        # Organization of G2Net: a/b/c/abc0123.npy\n",
    "        path_part = f\"{file_id[0]}/{file_id[1]}/{file_id[2]}\"\n",
    "        file_path = os.path.join(self.root_dir, path_part, f\"{file_id}.npy\")\n",
    "        \n",
    "        try:\n",
    "            waves = np.load(file_path).astype(np.float32)\n",
    "            \n",
    "            if self.stage == 'train' and self.augment:\n",
    "                waves = apply_timeshift(waves)\n",
    "\n",
    "            cleaned_waves = []\n",
    "            for i in range(3):\n",
    "                w = waves[i]\n",
    "                w = apply_bandpass(w)\n",
    "                w = apply_whitening(w)\n",
    "                w = w / (np.std(w) + 1e-20) \n",
    "                \n",
    "                cleaned_waves.append(w)\n",
    "            \n",
    "            waves = np.stack(cleaned_waves)\n",
    "            waves = torch.tensor(waves, dtype=torch.float32)\n",
    "            \n",
    "        except FileNotFoundError:\n",
    "            waves = torch.zeros((3, 4096), dtype=torch.float32)\n",
    "\n",
    "        if self.stage != 'test':\n",
    "            return waves, torch.tensor(row['target'], dtype=torch.float32)\n",
    "        return waves"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Configuration & Data Preparation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-25T15:05:54.443332Z",
     "iopub.status.busy": "2025-11-25T15:05:54.443005Z",
     "iopub.status.idle": "2025-11-25T15:05:54.914720Z",
     "shell.execute_reply": "2025-11-25T15:05:54.914073Z",
     "shell.execute_reply.started": "2025-11-25T15:05:54.443307Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data loaded. Shape: (560000, 3). Device: cuda\n"
     ]
    }
   ],
   "source": [
    "import utils\n",
    "\n",
    "class CFG:\n",
    "    debug = False          # Set to False for submission, True for quick debugging (10% data)\n",
    "    seed = 42\n",
    "    model_name = 'tf_efficientnet_b4_ns' \n",
    "    epochs = 12           \n",
    "    batch_size = 32   \n",
    "    lr = 1e-3\n",
    "    weight_decay = 1e-2\n",
    "    folds = 5\n",
    "    fold_idx = 0\n",
    "    num_workers = 2\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "utils.seed_everything(CFG.seed)\n",
    "config = utils.ProjectConfig()\n",
    "\n",
    "# Load and Split Data\n",
    "df = pd.read_csv(config.CSV_PATH)\n",
    "\n",
    "if CFG.debug:\n",
    "    df = df.sample(frac=0.1, random_state=CFG.seed).reset_index(drop=True)\n",
    "\n",
    "skf = StratifiedKFold(n_splits=CFG.folds, shuffle=True, random_state=CFG.seed)\n",
    "for fold, (_, val_idx) in enumerate(skf.split(df, df['target'])):\n",
    "    df.loc[val_idx, 'fold'] = fold\n",
    "\n",
    "print(f\"Data loaded. Shape: {df.shape}. Device: {CFG.device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Model Definition & Data Loaders**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-25T15:05:54.916635Z",
     "iopub.status.busy": "2025-11-25T15:05:54.916246Z",
     "iopub.status.idle": "2025-11-25T15:05:54.964421Z",
     "shell.execute_reply": "2025-11-25T15:05:54.963641Z",
     "shell.execute_reply.started": "2025-11-25T15:05:54.916615Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class G2NetModel(nn.Module):\n",
    "    def __init__(self, model_name, pretrained=True):\n",
    "        super().__init__()\n",
    "        self.wave_to_img = utils.WaveToImage(device=CFG.device)\n",
    "        self.batch_norm = nn.BatchNorm2d(3)\n",
    "        self.backbone = timm.create_model(model_name, pretrained=pretrained, in_chans=3, num_classes=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.wave_to_img(x)\n",
    "        x = self.batch_norm(x)\n",
    "        x = self.backbone(x)\n",
    "        return x\n",
    "\n",
    "# Dataset & Loader Initialization\n",
    "train_df = df[df['fold'] != CFG.fold_idx].reset_index(drop=True)\n",
    "valid_df = df[df['fold'] == CFG.fold_idx].reset_index(drop=True)\n",
    "\n",
    "train_ds = utils.CustomDataset(train_df, config.DATA_DIR, stage='train', augment=True)\n",
    "valid_ds = utils.CustomDataset(valid_df, config.DATA_DIR, stage='train', augment=False)\n",
    "\n",
    "train_loader = DataLoader(train_ds, \n",
    "                          batch_size=CFG.batch_size, \n",
    "                          shuffle=True, \n",
    "                          num_workers=CFG.num_workers, \n",
    "                          pin_memory=True,\n",
    "                          persistent_workers=True,\n",
    "                          prefetch_factor=2)\n",
    "\n",
    "valid_loader = DataLoader(valid_ds, \n",
    "                          batch_size=CFG.batch_size, \n",
    "                          shuffle=False, \n",
    "                          num_workers=CFG.num_workers, \n",
    "                          pin_memory=True,\n",
    "                          persistent_workers=True,\n",
    "                          prefetch_factor=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Training Engine**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-25T15:05:54.965351Z",
     "iopub.status.busy": "2025-11-25T15:05:54.965147Z",
     "iopub.status.idle": "2025-11-26T01:36:01.372559Z",
     "shell.execute_reply": "2025-11-26T01:36:01.368558Z",
     "shell.execute_reply.started": "2025-11-25T15:05:54.965335Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training for 12 epochs...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train:   0%|          | 0/14000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Valid:   0%|          | 0/3500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/12 | Loss: 0.6064 | AUC: 0.84145\n",
      " -> Saved Best Model: best_model_fold_0.pth (AUC: 0.84145)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train:   0%|          | 0/14000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Valid:   0%|          | 0/3500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/12 | Loss: 0.5179 | AUC: 0.84870\n",
      " -> Saved Best Model: best_model_fold_0.pth (AUC: 0.84870)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train:   0%|          | 0/14000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Valid:   0%|          | 0/3500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/12 | Loss: 0.5128 | AUC: 0.85282\n",
      " -> Saved Best Model: best_model_fold_0.pth (AUC: 0.85282)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train:   0%|          | 0/14000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Valid:   0%|          | 0/3500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/12 | Loss: 0.5057 | AUC: 0.85417\n",
      " -> Saved Best Model: best_model_fold_0.pth (AUC: 0.85417)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train:   0%|          | 0/14000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Valid:   0%|          | 0/3500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/12 | Loss: 0.5007 | AUC: 0.85618\n",
      " -> Saved Best Model: best_model_fold_0.pth (AUC: 0.85618)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train:   0%|          | 0/14000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Valid:   0%|          | 0/3500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/12 | Loss: 0.4949 | AUC: 0.85950\n",
      " -> Saved Best Model: best_model_fold_0.pth (AUC: 0.85950)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train:   0%|          | 0/14000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Valid:   0%|          | 0/3500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/12 | Loss: 0.4904 | AUC: 0.86043\n",
      " -> Saved Best Model: best_model_fold_0.pth (AUC: 0.86043)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train:   0%|          | 0/14000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Valid:   0%|          | 0/3500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/12 | Loss: 0.4872 | AUC: 0.86105\n",
      " -> Saved Best Model: best_model_fold_0.pth (AUC: 0.86105)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train:   0%|          | 0/14000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Valid:   0%|          | 0/3500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/12 | Loss: 0.4829 | AUC: 0.86310\n",
      " -> Saved Best Model: best_model_fold_0.pth (AUC: 0.86310)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train:   0%|          | 0/14000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Valid:   0%|          | 0/3500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/12 | Loss: 0.4809 | AUC: 0.86347\n",
      " -> Saved Best Model: best_model_fold_0.pth (AUC: 0.86347)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train:   0%|          | 0/14000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Valid:   0%|          | 0/3500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11/12 | Loss: 0.4775 | AUC: 0.86397\n",
      " -> Saved Best Model: best_model_fold_0.pth (AUC: 0.86397)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train:   0%|          | 0/14000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Valid:   0%|          | 0/3500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12/12 | Loss: 0.4751 | AUC: 0.86405\n",
      " -> Saved Best Model: best_model_fold_0.pth (AUC: 0.86405)\n",
      "Training complete. Best AUC: 0.86405\n"
     ]
    }
   ],
   "source": [
    "def mixup_data(x, y, alpha=0.2):\n",
    "    '''Returns mixed inputs, pairs of targets, and lambda'''\n",
    "    if alpha > 0:\n",
    "        lam = np.random.beta(alpha, alpha)\n",
    "    else:\n",
    "        lam = 1\n",
    "\n",
    "    batch_size = x.size(0)\n",
    "    index = torch.randperm(batch_size).to(x.device)\n",
    "\n",
    "    mixed_x = lam * x + (1 - lam) * x[index, :]\n",
    "    y_a, y_b = y, y[index]\n",
    "    return mixed_x, y_a, y_b, lam\n",
    "\n",
    "def mixup_criterion(criterion, pred, y_a, y_b, lam):\n",
    "    return lam * criterion(pred, y_a) + (1 - lam) * criterion(pred, y_b)\n",
    "\n",
    "def train_one_epoch(model, loader, optimizer, criterion, scaler, scheduler=None):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    pbar = tqdm(loader, desc=\"Train\", leave=False)\n",
    "    \n",
    "    for waves, labels in pbar:\n",
    "        waves = waves.to(CFG.device)\n",
    "        labels = labels.to(CFG.device).unsqueeze(1)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # --- 1. MIXUP ---\n",
    "        mixed_waves, labels_a, labels_b, lam = mixup_data(waves, labels, alpha=0.2)\n",
    "        \n",
    "        with autocast(): \n",
    "            outputs = model(mixed_waves)\n",
    "            loss = mixup_criterion(criterion, outputs, labels_a, labels_b, lam)\n",
    "            \n",
    "        scaler.scale(loss).backward()\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "        \n",
    "        # --- 2. SCHEDULER STEP ---\n",
    "        if scheduler is not None:\n",
    "            scheduler.step() \n",
    "        \n",
    "        running_loss += loss.item()\n",
    "        pbar.set_postfix(loss=f\"{loss.item():.4f}\", lr=f\"{optimizer.param_groups[0]['lr']:.1e}\")\n",
    "        \n",
    "    return running_loss / len(loader)\n",
    "\n",
    "@torch.no_grad()\n",
    "def validate(model, loader):\n",
    "    model.eval()\n",
    "    preds, targets = [], []\n",
    "    \n",
    "    for waves, labels in tqdm(loader, desc=\"Valid\", leave=False):\n",
    "        waves = waves.to(CFG.device)\n",
    "        outputs = model(waves)\n",
    "        probs = torch.sigmoid(outputs).squeeze()\n",
    "        \n",
    "        if torch.isnan(probs).any():\n",
    "            probs = torch.nan_to_num(probs, nan=0.0)\n",
    "            \n",
    "        preds.extend(probs.cpu().numpy())\n",
    "        targets.extend(labels.numpy())\n",
    "        \n",
    "    return roc_auc_score(targets, preds)\n",
    "\n",
    "# --- Main Loop ---\n",
    "model = G2NetModel(CFG.model_name).to(CFG.device)\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=CFG.lr, weight_decay=CFG.weight_decay)\n",
    "scheduler = torch.optim.lr_scheduler.OneCycleLR(\n",
    "    optimizer,\n",
    "    max_lr=CFG.lr,               \n",
    "    epochs=CFG.epochs,           \n",
    "    steps_per_epoch=len(train_loader), \n",
    "    pct_start=0.3,               \n",
    "    div_factor=25.0,            \n",
    "    final_div_factor=1000.0    \n",
    ")\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "scaler = torch.cuda.amp.GradScaler()\n",
    "best_auc = 0.0\n",
    "\n",
    "print(f\"Starting training for {CFG.epochs} epochs...\")\n",
    "\n",
    "for epoch in range(CFG.epochs):\n",
    "    train_loss = train_one_epoch(model, train_loader, optimizer, criterion, scaler, scheduler)\n",
    "    val_auc = validate(model, valid_loader)\n",
    "    \n",
    "    print(f\"Epoch {epoch+1}/{CFG.epochs} | Loss: {train_loss:.4f} | AUC: {val_auc:.5f}\")\n",
    "    \n",
    "    if val_auc > best_auc:\n",
    "        best_auc = val_auc\n",
    "        save_name = f\"best_model_fold_{CFG.fold_idx}.pth\"\n",
    "        torch.save(model.state_dict(), save_name) \n",
    "        print(f\" -> Saved Best Model: {save_name} (AUC: {best_auc:.5f})\")\n",
    "\n",
    "print(f\"Training complete. Best AUC: {best_auc:.5f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Inference & Submission**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-26T01:36:01.379751Z",
     "iopub.status.busy": "2025-11-26T01:36:01.379469Z",
     "iopub.status.idle": "2025-11-26T02:04:13.251804Z",
     "shell.execute_reply": "2025-11-26T02:04:13.250923Z",
     "shell.execute_reply.started": "2025-11-26T01:36:01.379723Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating submission...\n",
      "Loaded best model weights from best_model_fold_0.pth\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b5f57de2532446faac8129594d76a781",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Predicting:   0%|          | 0/7063 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submission saved to 'submission.csv'\n"
     ]
    }
   ],
   "source": [
    "print(\"Generating submission...\")\n",
    "\n",
    "sample_sub = pd.read_csv('/kaggle/input/g2net-gravitational-wave-detection/sample_submission.csv')\n",
    "test_ds = utils.CustomDataset(\n",
    "    sample_sub, \n",
    "    config.DATA_DIR.replace('train', 'test'), \n",
    "    stage='test', \n",
    "    augment=False\n",
    ")\n",
    "test_loader = DataLoader(test_ds, batch_size=CFG.batch_size, shuffle=False, num_workers=CFG.num_workers)\n",
    "\n",
    "weights_path = f\"best_model_fold_{CFG.fold_idx}.pth\"\n",
    "\n",
    "if os.path.exists(weights_path):\n",
    "    checkpoint = torch.load(weights_path, map_location=CFG.device)\n",
    "    new_state_dict = {}\n",
    "    for k, v in checkpoint.items():\n",
    "        name = k.replace(\"_orig_mod.\", \"\") \n",
    "        new_state_dict[name] = v\n",
    "        \n",
    "    model.load_state_dict(new_state_dict)\n",
    "    print(f\"Loaded best model weights from {weights_path}\")\n",
    "else:\n",
    "    print(f\"Warning: {weights_path} not found. Using current weights.\")\n",
    "\n",
    "model.eval()\n",
    "\n",
    "test_preds = []\n",
    "with torch.no_grad():\n",
    "    for waves in tqdm(test_loader, desc=\"Predicting\"):\n",
    "        waves = waves.to(CFG.device)\n",
    "        outputs = model(waves)\n",
    "        probs = torch.sigmoid(outputs).squeeze()\n",
    "        \n",
    "        if probs.ndim == 0:\n",
    "            test_preds.append(probs.item())\n",
    "        else:\n",
    "            test_preds.extend(probs.cpu().numpy())\n",
    "\n",
    "sample_sub['target'] = test_preds\n",
    "sample_sub.to_csv('submission.csv', index=False)\n",
    "print(\"Submission saved to 'submission.csv'\")"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "databundleVersionId": 2399555,
     "sourceId": 23249,
     "sourceType": "competition"
    }
   ],
   "dockerImageVersionId": 31193,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
