{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":23249,"databundleVersionId":2399555,"sourceType":"competition"}],"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Imports","metadata":{}},{"cell_type":"code","source":"import os\nimport warnings\nimport random\nimport numpy as np\nimport pandas as pd\nimport torch\nimport torch.nn as nn\nimport timm\nimport scipy.signal\nfrom scipy.signal.windows import tukey\nfrom torch.utils.data import DataLoader, Dataset\nfrom torch.cuda.amp import autocast, GradScaler\nfrom tqdm.auto import tqdm\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn.metrics import roc_auc_score\n\n# Turn of warning \nwarnings.filterwarnings('ignore')\n\n# Check nnAudio lib\ntry:\n    from nnAudio.Spectrogram import CQT1992v2\n    print(\"Library nnAudio imported successfully!\")\nexcept ImportError:\n    print(\"Warning: nnAudio not installed. Please pip install nnAudio.\")","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Configuration","metadata":{}},{"cell_type":"code","source":"class CFG:\n    debug = False       \n    train = True          \n    seed = 42\n    model_name = 'tf_efficientnet_b4_ns' \n    epochs = 12           \n    batch_size = 32   \n    lr = 1e-3\n    weight_decay = 1e-2\n    folds = 5         \n    num_workers = 2\n    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\n    # Path \n    ROOT_DIR = '/kaggle/working'\n    DATA_DIR = '/kaggle/input/g2net-gravitational-wave-detection/train'\n    TEST_DIR = '/kaggle/input/g2net-gravitational-wave-detection/test'\n    CSV_PATH = '/kaggle/input/g2net-gravitational-wave-detection/training_labels.csv'\n    SAMPLE_SUB = '/kaggle/input/g2net-gravitational-wave-detection/sample_submission.csv'\n\ndef seed_everything(seed=42):\n    random.seed(seed)\n    os.environ['PYTHONHASHSEED'] = str(seed)\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    if torch.cuda.is_available():\n        torch.cuda.manual_seed(seed)\n        torch.backends.cudnn.benchmark = True \n\nseed_everything(CFG.seed)\nprint(f\"Device: {CFG.device}\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Signal Processing Utils","metadata":{}},{"cell_type":"code","source":"SOS_FILTER = scipy.signal.butter(4, [20, 500], btype=\"bandpass\", output=\"sos\", fs=2048)\nNORMALIZATION_FACTOR = np.sqrt((500 - 20) / (2048 / 2))\nWINDOW_TUKEY = tukey(4096, alpha=0.1)\n\ndef apply_bandpass(x):\n    return scipy.signal.sosfiltfilt(SOS_FILTER, x) / NORMALIZATION_FACTOR\n\ndef apply_whitening(x, sr=2048):\n    x = x * WINDOW_TUKEY\n    freqs, psd = scipy.signal.welch(x, fs=sr, nperseg=sr, window='hann')\n    \n    x_f = np.fft.rfft(x)\n    freqs_f = np.fft.rfftfreq(len(x), d=1/sr)\n    \n    valid_indices = (freqs_f >= freqs.min()) & (freqs_f <= freqs.max())\n    x_f_whitened = np.zeros_like(x_f)\n    \n    psd_values = np.interp(freqs_f[valid_indices], freqs, psd)\n    x_f_whitened[valid_indices] = x_f[valid_indices] / np.sqrt(psd_values + 1e-20)\n    \n    return np.fft.irfft(x_f_whitened, n=len(x))\n\ndef apply_timeshift(x, max_shift=0.2, sr=2048):\n    shift_amt = int(np.random.random() * max_shift * sr)\n    if np.random.random() > 0.5:\n        shift_amt = -shift_amt\n    return np.roll(x, shift_amt, axis=-1)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Dataset & DataLoader","metadata":{}},{"cell_type":"code","source":"class CustomDataset(Dataset):\n    def __init__(self, dataframe, root_dir, stage='train', augment=False):\n        self.df = dataframe\n        self.root_dir = root_dir\n        self.stage = stage\n        self.augment = augment\n\n    def __len__(self):\n        return len(self.df)\n\n    def __getitem__(self, idx):\n        row = self.df.iloc[idx]\n        file_id = str(row['id'])\n        path_part = f\"{file_id[0]}/{file_id[1]}/{file_id[2]}\"\n        file_path = os.path.join(self.root_dir, path_part, f\"{file_id}.npy\")\n        \n        try:\n            waves = np.load(file_path).astype(np.float32)\n            \n            if self.stage == 'train' and self.augment:\n                waves = apply_timeshift(waves)\n            \n            # Preprocessing Pipeline\n            cleaned_waves = []\n            for i in range(3):\n                w = waves[i]\n                w = apply_bandpass(w)       # Step 1: Bandpass\n                w = apply_whitening(w)      # Step 2: Whitening\n                w = w / (np.std(w) + 1e-20) # Step 3: Normalization \n                cleaned_waves.append(w)\n            \n            waves = np.stack(cleaned_waves)\n            waves = torch.tensor(waves, dtype=torch.float32)\n            \n        except FileNotFoundError:\n            waves = torch.zeros((3, 4096), dtype=torch.float32)\n\n        if self.stage != 'test':\n            return waves, torch.tensor(row['target'], dtype=torch.float32)\n        return waves","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# EfficientNet-B4","metadata":{}},{"cell_type":"code","source":"class WaveToImage(nn.Module):\n    def __init__(self, sr=2048, fmin=20, fmax=1024, hop_length=64):\n        super().__init__()\n        self.transform = CQT1992v2(sr=sr, fmin=fmin, fmax=fmax, hop_length=hop_length, \n                                   output_format=\"Magnitude\", verbose=False)\n    \n    def forward(self, x):\n        batch_size, channels, time_steps = x.shape\n        x = x.view(batch_size * channels, time_steps)\n        images = self.transform(x)\n        _, h, w = images.shape\n        return images.view(batch_size, channels, h, w)\n\nclass G2NetModel(nn.Module):\n    def __init__(self, model_name, pretrained=True):\n        super().__init__()\n        self.wave_to_img = WaveToImage()\n        # Batch Norm\n        self.batch_norm = nn.BatchNorm2d(3)\n        self.backbone = timm.create_model(model_name, pretrained=pretrained, in_chans=3, num_classes=1)\n\n    def forward(self, x):\n        x = self.wave_to_img(x)\n        x = self.batch_norm(x)\n        x = self.backbone(x)\n        return x","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Mixup, Train Loop","metadata":{}},{"cell_type":"code","source":"# Mixup Augmentation\ndef mixup_data(x, y, alpha=0.2):\n    if alpha > 0:\n        lam = np.random.beta(alpha, alpha)\n    else:\n        lam = 1\n    batch_size = x.size(0)\n    index = torch.randperm(batch_size).to(x.device)\n    mixed_x = lam * x + (1 - lam) * x[index, :]\n    y_a, y_b = y, y[index]\n    return mixed_x, y_a, y_b, lam\n\ndef mixup_criterion(criterion, pred, y_a, y_b, lam):\n    return lam * criterion(pred, y_a) + (1 - lam) * criterion(pred, y_b)\n\n# Training Step\ndef train_fn(model, loader, optimizer, criterion, scaler, scheduler):\n    model.train()\n    running_loss = 0.0\n    for waves, labels in tqdm(loader, desc=\"Train\", leave=False):\n        waves = waves.to(CFG.device)\n        labels = labels.to(CFG.device).unsqueeze(1)\n        optimizer.zero_grad()\n        \n        mixed_waves, labels_a, labels_b, lam = mixup_data(waves, labels, alpha=0.2)\n        \n        with autocast():\n            outputs = model(mixed_waves)\n            loss = mixup_criterion(criterion, outputs, labels_a, labels_b, lam)\n        \n        scaler.scale(loss).backward()\n        scaler.step(optimizer)\n        scaler.update()\n        if scheduler: scheduler.step()\n        \n        running_loss += loss.item()\n    return running_loss / len(loader)\n\n# Validation Step\n@torch.no_grad()\ndef valid_fn(model, loader):\n    model.eval()\n    preds, targets = [], []\n    for waves, labels in tqdm(loader, desc=\"Valid\", leave=False):\n        waves = waves.to(CFG.device)\n        outputs = model(waves)\n        probs = torch.sigmoid(outputs).squeeze()\n        preds.extend(probs.cpu().numpy())\n        targets.extend(labels.numpy())\n    return roc_auc_score(targets, preds)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Main","metadata":{}},{"cell_type":"code","source":"if __name__ == '__main__':\n    df = pd.read_csv(CFG.CSV_PATH)\n    if CFG.debug: \n        df = df.sample(frac=0.05).reset_index(drop=True)\n        print(\"DEBUG MODE: Using 5% data\")\n    \n    # Stratified K-Fold\n    skf = StratifiedKFold(n_splits=CFG.folds, shuffle=True, random_state=CFG.seed)\n    for fold, (_, val_idx) in enumerate(skf.split(df, df['target'])):\n        df.loc[val_idx, 'fold'] = fold\n\n    # Training Loop\n    if CFG.train:\n        print(f\"Start Training: {CFG.folds} Folds\")\n        \n        for fold in range(CFG.folds):\n            print(f\"\\n>>> TRAINING FOLD {fold} <<<\")\n            \n            # Train/Valid\n            train_idx = df[df['fold'] != fold].index\n            valid_idx = df[df['fold'] == fold].index\n            \n            train_ds = CustomDataset(df.iloc[train_idx], CFG.DATA_DIR, 'train', augment=True)\n            valid_ds = CustomDataset(df.iloc[valid_idx], CFG.DATA_DIR, 'valid', augment=False)\n            \n            train_loader = DataLoader(train_ds, batch_size=CFG.batch_size, shuffle=True, \n                                      num_workers=CFG.num_workers, pin_memory=True)\n            valid_loader = DataLoader(valid_ds, batch_size=CFG.batch_size, shuffle=False, \n                                      num_workers=CFG.num_workers, pin_memory=True)\n            \n            # Model & Optimizer\n            model = G2NetModel(CFG.model_name).to(CFG.device)\n            optimizer = torch.optim.AdamW(model.parameters(), lr=CFG.lr, weight_decay=CFG.weight_decay)\n            scheduler = torch.optim.lr_scheduler.OneCycleLR(optimizer, max_lr=CFG.lr, \n                                                            epochs=CFG.epochs, \n                                                            steps_per_epoch=len(train_loader), \n                                                            pct_start=0.3)\n            criterion = nn.BCEWithLogitsLoss()\n            scaler = torch.cuda.amp.GradScaler()\n            \n            # Loop Epochs\n            best_score = 0.0\n            for epoch in range(CFG.epochs):\n                train_loss = train_fn(model, train_loader, optimizer, criterion, scaler, scheduler)\n                val_score = valid_fn(model, valid_loader)\n                print(f\"Epoch {epoch+1} | Loss: {train_loss:.4f} | AUC: {val_score:.5f}\")\n                \n                if val_score > best_score:\n                    best_score = val_score\n                    torch.save(model.state_dict(), f\"best_model_fold_{fold}.pth\")\n                    print(f\"Saved Best Model Fold {fold}: {best_score:.5f}\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Inference & Ensemble","metadata":{}},{"cell_type":"code","source":"print(\"\\nStarting Ensemble Inference...\")\n\nsample_sub = pd.read_csv(CFG.SAMPLE_SUB)\ntest_ds = CustomDataset(sample_sub, CFG.TEST_DIR, stage='test', augment=False)\ntest_loader = DataLoader(test_ds, batch_size=CFG.batch_size * 2, shuffle=False, num_workers=CFG.num_workers)\n\nfinal_preds = np.zeros(len(sample_sub))\n\nfor fold in range(CFG.folds):\n    weight_path = f\"best_model_fold_{fold}.pth\"\n    \n    if not os.path.exists(weight_path):\n        print(f\"Warning: Weights for Fold {fold} not found. Skipping...\")\n        continue\n        \n    print(f\"Inference using Fold {fold}...\")\n    \n    # Load model\n    model = G2NetModel(CFG.model_name, pretrained=False).to(CFG.device)\n    model.load_state_dict(torch.load(weight_path, map_location=CFG.device))\n    model.eval()\n    \n    # Prediction\n    fold_preds = []\n    with torch.no_grad():\n        for waves in tqdm(test_loader, desc=f\"Pred Fold {fold}\"):\n            waves = waves.to(CFG.device)\n            outputs = model(waves)\n            probs = torch.sigmoid(outputs).squeeze().cpu().numpy()\n            fold_preds.extend(probs)\n    \n    final_preds += np.array(fold_preds) / CFG.folds\n\nsample_sub['target'] = final_preds\nsample_sub.to_csv('submission.csv', index=False)\nprint(\"Ensemble Submission Saved Successfully!\")\nprint(sample_sub.head())","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}